# Filters

Filters in Linux are commands that process text streams and produce output that can be used in further processing. They are an integral part of shell scripting and command-line operations, especially when working with pipelines (`|`), where the output of one command is used as input for another.

This page will cover some of the most commonly used filters in Linux, including `cat`, `grep`, `sort`, `uniq`, `cut`, `tr`, and `sed`.

## `cat`: Concatenate and Display Files

The `cat` command reads files sequentially, writing their contents to the standard output. It’s often used to display the contents of files or to concatenate multiple files into one.

### Basic Usage

- **Display a File**: 

    ```bash
    cat filename
    ```

- **Concatenate Multiple Files**: 

    ```bash
    cat file1 file2 > combinedfile
    ```

- **Display Line Numbers**: 

    ```bash
    cat -n filename
    ```

## `grep`: Search Text Using Patterns

The `grep` command searches through text using patterns (regular expressions). It’s commonly used to find specific lines in a file that match a pattern.

### Basic Usage

- **Search for a Pattern in a File**:

    ```bash
    grep "pattern" filename
    ```

- **Search Recursively in a Directory**:

    ```bash
    grep -r "pattern" directory/
    ```

- **Show Line Numbers**:

    ```bash
    grep -n "pattern" filename
    ```

- **Ignore Case**:

    ```bash
    grep -i "pattern" filename
    ```

## `sort`: Sort Text

The `sort` command sorts lines in a file alphabetically or numerically.

### Basic Usage

- **Sort a File Alphabetically**:

    ```bash
    sort filename
    ```

- **Sort Numerically**:

    ```bash
    sort -n filename
    ```

- **Sort in Reverse Order**:

    ```bash
    sort -r filename
    ```

- **Sort by a Specific Field**:

    ```bash
    sort -k 2 filename
    ```

## `uniq`: Report or Omit Repeated Lines

The `uniq` command filters out repeated lines in a file, often used in conjunction with `sort`.

### Basic Usage

- **Remove Duplicate Lines**:

    ```bash
    sort filename | uniq
    ```

- **Count Occurrences of Lines**:

    ```bash
    sort filename | uniq -c
    ```

- **Only Print Duplicate Lines**:

    ```bash
    sort filename | uniq -d
    ```

## `cut`: Remove Sections from Each Line

The `cut` command extracts sections from each line of input, typically used to extract columns from text files or command outputs.

### Basic Usage

- **Extract the First Column**:

    ```bash
    cut -d ' ' -f 1 filename
    ```

    - `-d ' '` specifies the delimiter (a space in this case).
    - `-f 1` specifies the first field (column).

- **Extract Multiple Columns**:

    ```bash
    cut -d ',' -f 1,3 filename
    ```

    This example extracts the first and third columns from a CSV file.

## `tr`: Translate or Delete Characters

The `tr` command is used for translating or deleting characters from text input.

### Basic Usage

- **Convert Lowercase to Uppercase**:

    ```bash
    tr 'a-z' 'A-Z'
    ```

- **Delete Specific Characters**:

    ```bash
    tr -d 'a'
    ```

    This removes all instances of the letter `a` from the input.

- **Replace a Character**:

    ```bash
    tr ' ' '_'
    ```

    This replaces all spaces with underscores.

## `sed`: Stream Editor

The `sed` command is a powerful stream editor for filtering and transforming text.

### Basic Usage

- **Substitute a Word**:

    ```bash
    sed 's/oldword/newword/' filename
    ```

    - `s` indicates substitution.
    - `oldword` is the word to be replaced.
    - `newword` is the replacement word.

- **Substitute Globally on a Line**:

    ```bash
    sed 's/oldword/newword/g' filename
    ```

    The `g` at the end makes the substitution global, replacing all instances of `oldword` on each line.

- **Delete a Line Containing a Pattern**:

    ```bash
    sed '/pattern/d' filename
    ```

- **Print Only Matching Lines**:

    ```bash
    sed -n '/pattern/p' filename
    ```

## Combining Filters

Filters can be combined using pipes (`|`) to perform more complex text processing tasks.

### Example: Extracting and Sorting Data

Imagine you have a log file and you want to extract all IP addresses, remove duplicates, and sort them:

```bash
grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' logfile | sort | uniq
```

- `grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+'` extracts all IP addresses.
- `sort` sorts the IP addresses.
- `uniq` removes duplicates.

